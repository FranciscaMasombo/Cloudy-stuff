### Configuring OpenShift Networking for Applications

In OpenShift Container Platform, the SDN satisfies the following five requirements:
1. Managing the network traffic and network resources programmatically, so that the organization teams can decide how to expose their applications.
2. Managing communication between containers that run in the same project.
3. Managing communication between pods, whether they belong to a same project or run in separate projects.
4. Managing network communication from a pod to a service.
5. Managing network communication from an external network to a service, or from containers to external networks.

"Using Services for Accessing Pods"
In Kubernetes and OpenShift refers to a common pattern for accessing pods in a cluster. A Service is a Kubernetes resource that provides a stable IP address and DNS name for pods, allowing them to be accessed from within the cluster and from outside the cluster. Services are used to abstract the underlying pods and provide a stable, reliable way to access them, even if the pods themselves are recreated or rescheduled.

When a service is created, it is associated with a set of pods, and it acts as a load balancer for the pods, distributing incoming requests to the pods. Services provide a stable IP address and DNS name for the pods, so that they can be accessed by other pods, services, and external clients. The IP address and DNS name of a service do not change, even if the pods associated with the service are recreated or rescheduled, making it easier to manage and maintain your applications.

Using services to access pods has several benefits:

Abstraction: Services provide an abstraction layer between the underlying pods and the clients accessing them, making it easier to manage and maintain your applications.

Load balancing: Services distribute incoming requests across the pods associated with the service, providing load balancing and improving reliability.

Resilience: Services provide a stable IP address and DNS name for the pods, even if the pods are recreated or rescheduled, improving resilience and reducing downtime.

Scalability: Services make it easy to scale the number of pods associated with a service, making it easy to manage the load on your applications.

In OpenShift, services are a key component of the platform's networking model and are used to provide access to pods from within the cluster and from outside the cluster. Services can be created and managed using the OpenShift API or CLI, and they provide a flexible and scalable way to manage access to pods in the cluster.

You must create a route to access the application from an external network. 
```
$ oc expose service frontend  --hostname todo.apps.ocp4.example.com
```
The JSONPath expression allows you to retrieve the service IP.
```
oc get service/mysql -o jsonpath="{.spec.clusterIP}{'\n'}"
```
Run the oc debug command against the frontend deployment
```
oc debug -t deployment/frontend
sh-4.4$ curl -v telnet://172.30.103.29:3306
```
List the services in the project and ensure that the frontend service exists
```
oc get svc
```
###Ingress traffic
Ingress traffic refers to the incoming network traffic to a cluster or a service in a cluster. In Kubernetes and OpenShift, ingress traffic is typically used to access services and applications running in the cluster from outside the cluster.

An Ingress resource in Kubernetes is a configuration object that allows inbound connections to reach the cluster-hosted services. The Ingress resource defines rules for routing incoming traffic to the correct service based on the hostname and/or URL path. Ingress traffic is usually managed by an Ingress controller, which is a piece of software that runs within the cluster and implements the rules defined in the Ingress resource.

In OpenShift, ingress traffic is typically managed using the OpenShift Router, which is a built-in component of the platform that implements the Ingress resource specification. The OpenShift Router provides a flexible and scalable way to manage incoming traffic to the cluster, and it supports features like load balancing, SSL termination, and route prioritization.

Ingress traffic is a critical component of the network architecture of a cluster, and it provides a flexible and scalable way to manage incoming traffic to services and applications running in the cluster. By managing ingress traffic, you can control how incoming requests are handled and ensure that they are routed to the correct service based on the hostname and/or URL path.

Route
Routes provide ingress traffic to services in the cluster. Routes were created before Kubernetes ingress objects and provide more features. Routes provide advanced features that may not be supported by Kubernetes ingress controllers through a standard interface, such as TLS re-encryption, TLS passthrough, and split traffic for blue-green deployments.

Ingress
An ingress is a Kubernetes resource that provides some of the same features as routes (which are an OpenShift resource). Ingresses accept external requests and proxy them based on the route. You can only allow certain types of traffic: HTTP, HTTPS and server name identification (SNI), and TLS with SNI. In OpenShift, routes are generated to meet the conditions specified by the ingress object.

There are alternatives to ingress and routes, but they are for special use cases. The following service types provide external access to services:

External load balancer
This resource instructs OpenShift to spin up a load balancer in a cloud environment. A load balancer instructs OpenShift to interact with the cloud provider in which the cluster is running to provision a load balancer.

Service external IP
This method instructs OpenShift to set NAT rules to redirect traffic from one of the cluster IPs to the container.

NodePort
With this method, OpenShift exposes a service on a static port on the node IP address. You must ensure that the external IP addresses are properly routed to the nodes.


### Exposing Applications for External Access

Run the oc expose command to create a route for accessing the application. 
```
oc expose svc todo-http --hostname todo-http.apps.ocp4.example.com
```

Generate TLS certificates for the application.
Generate the private key for your CA-signed certificate.
```
openssl genrsa -out training.key 4096
```
Generate the certificate signing request (CSR)
```
openssl req -new -key training.key -out training.csr -subj "/C=US/ST=North Carolina/L=Raleigh/O=Red Hat/ CN=todo-https.apps.ocp4.example.com"
```
Create a tls OpenShift secret named todo-certs. Use the --cert and --key options to embed the TLS certificates. Use training.crt as the certificate, and training.key as the key.
```
oc create secret tls todo-certs --cert certs/training.crt --key certs/training.key
```
Create the secure route.
Run the oc create route command to define the new route:
``` 
oc create route passthrough todo-https --service todo-https --port 8443 --hostname todo-https.apps.ocp4.example.com
```











